<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>

    <title>@willemsleegers’s website - R</title>
    <link>/tags/r/</link>
    <description>All entries in R on website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
    <lastBuildDate>Tue, 06 Mar 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/r/" rel="self" type="application/rss+xml" />
    
      
      <item>
        <title>Colloquium talk: tidystats</title>
        <link>/talks/colloquium_06_03_2018/</link>
        <pubDate>Tue, 06 Mar 2018 00:00:00 +0000</pubDate>
        <author> (Willem Sleegers)</author>
        <guid>/talks/colloquium_06_03_2018/</guid>
        <description>&lt;div id=&#34;colloquium-talk-tidystats&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Colloquium talk: tidystats&lt;/h1&gt;
&lt;p&gt;On March 6th, 2018, I gave a colloquium talk at the methodology department of Tilburg University. You can view the slides here:&lt;/p&gt;
&lt;div id=&#34;view-slides&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;a href=&#34;colloquium_06_03_2018.html&#34;&gt;View slides&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      </item>
      
    
      
      <item>
        <title>Lab meeting talk: tidystats</title>
        <link>/talks/labmeeting_26_01_2018/</link>
        <pubDate>Fri, 26 Jan 2018 00:00:00 +0000</pubDate>
        <author> (Willem Sleegers)</author>
        <guid>/talks/labmeeting_26_01_2018/</guid>
        <description>&lt;div id=&#34;lab-meeting-talk-tidystats&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lab meeting talk: tidystats&lt;/h1&gt;
&lt;p&gt;On January 26th, 2018, I gave a lab meeting presentation on my R package called tidystats. You can see the slides here:&lt;/p&gt;
&lt;div id=&#34;view-slides&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;a href=&#34;labmeeting_26_01_2018.html&#34;&gt;View slides&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      </item>
      
    
      
      <item>
        <title>Introducing tidystats</title>
        <link>/posts/introducing-tidystats/</link>
        <pubDate>Sat, 14 Oct 2017 00:00:00 +0000</pubDate>
        <author> (Willem Sleegers)</author>
        <guid>/posts/introducing-tidystats/</guid>
        <description>&lt;p&gt;I am very excited to announce my first ever R package, called &lt;code&gt;tidystats&lt;/code&gt;. Its function is to create a single text file containing the output of statistical models. This will enable researchers to store the results of their analyses not just in their manuscripts, but also in an organized file separate from their manuscript that they can freely share with anyone. In this blog post I will go into why I think it is useful to do this and how &lt;code&gt;tidystats&lt;/code&gt; works conceptually. For a tutorial I refer to the &lt;a href=&#34;https://github.com/WillemSleegers/tidystats&#34;&gt;README&lt;/a&gt; on Github and a future blog post.&lt;/p&gt;
&lt;div id=&#34;pdf-prisons&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;PDF prisons&lt;/h3&gt;
&lt;p&gt;The standard workflow of an academic researcher is to form hypotheses based on theory, collect data, analyse the results, and present these results in a manuscript. These results are very important. Not only are they used to test hypotheses, but they can also be used to check whether mistakes were made and to conduct meta-analyses. Checking for mistakes and summarizing results, as done with meta-analytic techniques, is vital for good science. We therefore want the data to be easily accessible. Unfortunately, this is often not the case. The output of statistical analyses is usually only found in the PDF file that is the researcher’s manuscript.&lt;/p&gt;
&lt;p&gt;Extracting data from PDFs using software is a possible solution, although it remains challenging. This is partly due to the file format itself. Sometimes a PDF is nothing but an image file, making it very difficult to extract text. In most cases, though, it’s because researchers flexibly report the results of their analyses (and rightly so). There are specific style guides (e.g., &lt;a href=&#34;http://www.apastyle.org&#34;&gt;APA&lt;/a&gt;) that determine how the output of certain analyses should be reported, but this is not sufficiently structured to make parsing PDF files easy. For example, a researcher may decide to report the results in the text, in a table, or in a graph. Or perhaps the researcher summarizes the results (e.g., all &lt;em&gt;Fs&lt;/em&gt; &amp;lt; 1), even though the separate results would be useful to the reader. This makes it either difficult, time-consuming, or impossible to get the required statistics.&lt;/p&gt;
&lt;p&gt;Thankfully, the difficulty of extracting text from PDFs hasn’t stopped some people from developing software tools to do this. For example, &lt;a href=&#34;http://statcheck.io&#34;&gt;statcheck&lt;/a&gt; is an R package to extract statistics from a PDF to see whether the results are consistent. In other words, it is a statistics spellchecker that can prevent the researcher from reporting incorrect statistics caused by mistyping or copy-paste errors (easy mistakes to make while writing up the results). There is also the &lt;a href=&#34;https://github.com/ropensci/tabulizer&#34;&gt;tabulizer&lt;/a&gt; package to extract results from tables in PDFs and there’s &lt;a href=&#34;https://arxiv.org/abs/1709.02261&#34;&gt;software&lt;/a&gt; to extract data from figures. However, each of these are not foolproof and require manual checking to see whether everything performed well.&lt;/p&gt;
&lt;p&gt;Another potential solution is to re-run the analyses yourself. Researchers are increasingly motivated to share the data and the scripts that were used to prepare and analyze the data. However, even though this is a great development, it is incredibly time-intensive to download other researcher’s data (which may be very large) and execute their scripts (which may not always be very well organized). Instead, I believe it is more fruitful for researchers to add an extra step in between their data analysis and manuscript preparation.&lt;/p&gt;
&lt;p&gt;I believe researchers should take all of the output of their statistical tests and put them together in a single data file. This data file should be organized so that data can easily be parsed.&lt;/p&gt;
&lt;p&gt;This is where &lt;code&gt;tidystats&lt;/code&gt; comes in.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tidystats&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Tidystats&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;tidystats&lt;/code&gt; is an R package that enables researchers to create a data file containing the output of statistical analyses. The basic workflow is quite simple. At the start of the data analysis script, an empty list is made that can store the output of statistical tests. Then, whenever a test is run, the output of the test can be added to the list. Once the data analysis stage is complete (and writing up the results begins), the list can be converted to a data frame and saved to a file.&lt;/p&gt;
&lt;p&gt;Organizing the output of statistical tests is not an easy feat because different analyses have different kinds of output. In other words, the collection of statistics resulting from different kinds of analyses is messy. A solution to messy data is to make it &lt;a href=&#34;http://vita.had.co.nz/papers/tidy-data.html&#34;&gt;tidy&lt;/a&gt;. Tidy data sets are easy to manipulate, model, and visualize because they have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. In the context of statistical analyses, relevant variables (e.g., type of analysis, the statistic, the value of the statistic) are columns, each relevant statistic (e.g., a &lt;em&gt;p&lt;/em&gt;-value of .054) is a row, and the statistical analysis is a table.&lt;/p&gt;
&lt;p&gt;To illustrate this, let’s conduct a typical regression analysis:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Run the regression
model &amp;lt;- lm(DV ~ condition, data = data)

# Inspect the output
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = DV ~ condition, data = data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.0710 -0.4938  0.0685  0.2462  1.3690 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)          5.0320     0.2202  22.850 9.55e-15 ***
## conditiontreatment  -0.3710     0.3114  -1.191    0.249    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.6964 on 18 degrees of freedom
## Multiple R-squared:  0.07308,    Adjusted R-squared:  0.02158 
## F-statistic: 1.419 on 1 and 18 DF,  p-value: 0.249&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output shows multiple statistics we would like to store. To get these we need to first extract them from the output of &lt;code&gt;summary(model)&lt;/code&gt; and then organize them. Inspired by the &lt;a href=&#34;https://github.com/tidyverse/broom&#34;&gt;&lt;code&gt;broom&lt;/code&gt;&lt;/a&gt; package, &lt;code&gt;tidystats&lt;/code&gt; contains functions to help tidy the output of these models. This consists of extracting the relevant statistics and put them in a format consistent with tidy data principles.&lt;/p&gt;
&lt;p&gt;Applying this to the &lt;code&gt;model&lt;/code&gt; variable, we get:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidystats::tidy_stats(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 16 x 5
##    term_nr term               statistic                   value method    
##      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;              &amp;lt;chr&amp;gt;                       &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     
##  1    1.00 (Intercept)        b                        5.03e⁺ ⁰ Linear re…
##  2    1.00 (Intercept)        SE                       2.20e⁻ ¹ Linear re…
##  3    1.00 (Intercept)        t                        2.29e⁺ ¹ Linear re…
##  4    1.00 (Intercept)        p                        9.55e⁻¹⁵ Linear re…
##  5    1.00 (Intercept)        df                       1.80e⁺ ¹ Linear re…
##  6    2.00 conditiontreatment b                       -3.71e⁻ ¹ Linear re…
##  7    2.00 conditiontreatment SE                       3.11e⁻ ¹ Linear re…
##  8    2.00 conditiontreatment t                       -1.19e⁺ ⁰ Linear re…
##  9    2.00 conditiontreatment p                        2.49e⁻ ¹ Linear re…
## 10    2.00 conditiontreatment df                       1.80e⁺ ¹ Linear re…
## 11    3.00 (Model)            R squared                7.31e⁻ ² Linear re…
## 12    3.00 (Model)            adjusted R squared       2.16e⁻ ² Linear re…
## 13    3.00 (Model)            F                        1.42e⁺ ⁰ Linear re…
## 14    3.00 (Model)            numerator df             1.00e⁺ ⁰ Linear re…
## 15    3.00 (Model)            denominator df           1.80e⁺ ¹ Linear re…
## 16    3.00 (Model)            p                        2.49e⁻ ¹ Linear re…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we see that the output is now organized in such a way that each column is a relevant variable, each row is a statistic, and the entire output is a table containing important statistics of the regression analysis. This allows us to then combine the output of &lt;em&gt;multiple&lt;/em&gt; statistical tests.&lt;/p&gt;
&lt;p&gt;However, before adding multiple results together, it might be useful to add additional information.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;adding-researcher-information&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Adding researcher information&lt;/h3&gt;
&lt;p&gt;Besides organizing the output of statistical tests, I also think researchers can add valuable information to specific tests. For example, when you want to perform a meta-analysis such as a p-curve analysis, you should not add all of the statistical results that you can find in the manuscript. Instead, only the results that belong to the effect of interest are relevant. Additional tests such as manipulation checks are not. It is easy to select statistics that do not belong to the effect of interest, as can be seen in this Data Colada &lt;a href=&#34;http://datacolada.org/60&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Something that may help make this easier is for the original authors to indicate what they consider to be the crucial tests.&lt;/p&gt;
&lt;p&gt;Additionally, it may be fruitful for researchers to also indicate which analyses were confirmatory and which were exploratory. For example, there is currently a debate about whether the alpha of .05 should be lowered to .005, see &lt;a href=&#34;https://psyarxiv.com/mky9j/&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;https://psyarxiv.com/9s3y6&#34;&gt;here&lt;/a&gt;, and &lt;a href=&#34;https://arxiv.org/abs/1709.07588&#34;&gt;here&lt;/a&gt;. Yet, the ‘correct’ alpha depends in part on whether an analysis is confirmatory or exploratory, so it may be fruitful for researchers to indicate whether the analysis was part of the pre-registration or not.&lt;/p&gt;
&lt;p&gt;To this end, &lt;code&gt;tidystats&lt;/code&gt; uses the &lt;code&gt;add_stats()&lt;/code&gt; function. This function tidies the output of a statistical test (as shown before) and allows researchers to add additional information, such as what type of test it is (e.g., hypothesis test, manipulation test) and whether the analysis is confirmatory or exploratory.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-benefits&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Additional benefits&lt;/h3&gt;
&lt;p&gt;I am making the case for researchers to add an additional step their workflow: to create an organized file containing the statistical output of the tests, together with additional researcher-supplied information. I realize that arguing for already-way-too-busy researchers to do extra work is not a particularly winning strategy. Of course I hope that my prior arguments are convincing in that this extra step will greatly boost the ease with which we can perform meta-analytic research, but if you are not interested in doing meta-analytic research, these arguments may be less persuasive. Thankfully, there are additional benefits to creating an organized data file.&lt;/p&gt;
&lt;p&gt;If you have an organized data file of statistical output, you can use this file to easily report the output in your manuscript. Using &lt;a href=&#34;http://rmarkdown.rstudio.com&#34;&gt;R Markdown&lt;/a&gt; it is possible to combine code together with text in order to write a results section. Some packages already exist to make this possible (e.g., &lt;a href=&#34;https://github.com/crsh/papaja&#34;&gt;papaja&lt;/a&gt;). Having an organized data file of statistics makes reporting the output of a statistical analysis as easy as saying ‘report results of analysis X’. In fact, &lt;code&gt;tidystats()&lt;/code&gt; currently supports exactly this for t-tests, correlations, regression, and ANOVAs. You can check out the &lt;a href=&#34;https://github.com/WillemSleegers/tidystats&#34;&gt;README&lt;/a&gt; to see some examples of how this works. This not only makes it easy to report statistics, it also prevents mistakes due to typos and copy-paste errors, which are surprisingly common (see for example &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5101263/&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;So, organizing a data file of statistics output is not just beneficial for conducting meta-research, it is also beneficial for individual researchers working on their manuscript.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;In this blog post I have tried to make the case for an extra step in the researcher’s workflow, and how &lt;code&gt;tidystats&lt;/code&gt; can be used to achieve this. My main goal is to convince you of the benefits of the former, and not necessarily of the benefits of the latter. I simply believe it is useful for researchers to organize the output of their statistical tests, rather than put them in PDF prisons. You do not need &lt;code&gt;tidystats&lt;/code&gt; to do this. You could even create your own technique for doing so. Nevertheless, I hope that &lt;code&gt;tidystats&lt;/code&gt; adds some value for researchers who often have to analyze data and share their results. I will continue to work on &lt;code&gt;tidystats&lt;/code&gt; to add support for even more statistical functions and even more reporting functions. If you want to help contribute to the package, you can do so &lt;a href=&#34;https://github.com/WillemSleegers/tidystats&#34;&gt;here&lt;/a&gt;. I also appreciate any feedback, so feel free to share your thoughts.&lt;/p&gt;
&lt;/div&gt;
</description>
      </item>
      
    
      
      <item>
        <title>Creating a trial-based time variable</title>
        <link>/posts/creating-a-trial-based-time-variable/</link>
        <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
        <author> (Willem Sleegers)</author>
        <guid>/posts/creating-a-trial-based-time-variable/</guid>
        <description>&lt;p&gt;One of the first issues I ran into when starting to analyze eye tracker data was that the raw data does not contain a trial-based time variable. I expected that the timestamp variable would be a variable that starts at 0 when a trial begins and that it would keep adding up at a rate equal to the sampling frequency, until the end of the trial. Instead, you are likely to get a timestamp variable that looks like a random set of numbers, as shown here:&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-1&#34;&gt;Table 1: &lt;/span&gt;Example data&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;subject&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;timestamp&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;trial&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;pupil&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212275472&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.732900&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212292222&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.742935&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212308845&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.739175&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212325470&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.759690&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212342094&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.753800&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212358844&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.755915&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212375469&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.770130&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212392094&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.760900&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212408718&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.767435&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212425344&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.755015&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The &lt;strong&gt;timestamp&lt;/strong&gt; variable actually reflects the internal clock of the hardware used to get the data. This means that each measurement recording has a specific clock time associated with it, rather than a time stamp related to an event in the experiment.&lt;/p&gt;
&lt;p&gt;Fortunately, it’s relatively easy to turn this variable into a more useful variable. What we want is a variable, say &lt;strong&gt;time&lt;/strong&gt;, that starts at 0 when a trial begins. The subsequent measures, in the same trial, should then be timed relative to the start of the trial. We want this for every trial.&lt;/p&gt;
&lt;p&gt;The required steps to get this variable are as follows:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;For each trial, get the minimum of the &lt;strong&gt;timestamp&lt;/strong&gt; variable (e.g., 212275472 in trial 1)&lt;/li&gt;
&lt;li&gt;Repeat this value across the entire trial&lt;/li&gt;
&lt;li&gt;Subtract this value from the &lt;strong&gt;timestamp&lt;/strong&gt; variable&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In R, this would look like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create a trial-based time variable
data %&amp;gt;%
    group_by(subject, trial) %&amp;gt;%
    mutate(time = timestamp - min(timestamp)) -&amp;gt; data

# Divide by a 1000 to have the variable denote milliseconds rather than microseconds
data$time &amp;lt;- data$time / 1000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We take our data frame, group the data by &lt;strong&gt;subject&lt;/strong&gt; and &lt;strong&gt;trial&lt;/strong&gt; (because we want the minimum for each individual trial), and create a new variable called &lt;strong&gt;time&lt;/strong&gt; that is equal to the value in &lt;strong&gt;timestamp&lt;/strong&gt; minus the minimum of the timestamp for that trial. Additionally, we divide the result by a 1000 because the internal clock is in microseconds, and I prefer milliseconds. The result is this:&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-2&#34;&gt;Table 2: &lt;/span&gt;Example data with time variable&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;subject&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;timestamp&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;trial&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;pupil&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212275472&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.732900&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212292222&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.742935&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16.750&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212308845&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.739175&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33.373&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212325470&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.759690&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;49.998&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212342094&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.753800&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;66.622&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212358844&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.755915&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212375469&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.770130&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16.625&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212392094&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.760900&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33.250&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212408718&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.767435&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;49.874&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212425344&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.755015&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;66.500&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We see that our new variable time indeed starts at 0, adds up until the next trial, where it starts at 0 again. Excellent!&lt;/p&gt;
</description>
      </item>
      
    
      
      <item>
        <title>Importing multiple data files</title>
        <link>/posts/importing-multiple-data-files/</link>
        <pubDate>Fri, 02 Jun 2017 00:00:00 +0000</pubDate>
        <author> (Willem Sleegers)</author>
        <guid>/posts/importing-multiple-data-files/</guid>
        <description>&lt;p&gt;Combining multiple data files is a regular problem for certain researchers, including myself. In my eye tracker research I collect data for each participant separately. This means that when I want to start preparing my data, I first need to combine the data into one large data frame.&lt;/p&gt;
&lt;p&gt;There are many ways to combine separate data files in R. You can read in each file separately and store the result in their own data frame, after which you merge them together. Depending on the number of files, this might be feasible. In cases where you have many files, this is not. You can also create a &lt;code&gt;for&lt;/code&gt; loop to loop across all the files and merge the data of each file into one data frame. This is an attractive solution, but R is not really made for &lt;code&gt;for&lt;/code&gt; loops. Instead, functions such as &lt;code&gt;lapply()&lt;/code&gt; can be used.&lt;/p&gt;
&lt;p&gt;But I recently discovered a better &lt;a href=&#34;https://github.com/STAT545-UBC/Discussion/issues/398&#34;&gt;way&lt;/a&gt; that also fits nicely in my preferred usage of R: the &lt;a href=&#34;http://tidyverse.org&#34;&gt;tidyverse&lt;/a&gt;. Using the &lt;code&gt;tidyverse&lt;/code&gt; package, you can read in multiple data files like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Read in all files in the current working directory and store the result in &amp;#39;data&amp;#39;
list.files() %&amp;gt;%
    map_df(read_tsv) -&amp;gt; data&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;list.files()&lt;/code&gt; returns a vector containing the file names of the files in your current working directory. This vector is piped into &lt;code&gt;map_df()&lt;/code&gt; with the pipe operator, &lt;code&gt;%&amp;gt;%&lt;/code&gt;. &lt;code&gt;map_df()&lt;/code&gt; loops over each of these files, reads in the data with the supplied function (in this case &lt;code&gt;read_tsv()&lt;/code&gt;), and automatically combines the results into one data frame, which I store in a variable called &lt;code&gt;data&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This code works if you are already in the correct working directory. If you do not want to set the working directory, you can add the &lt;code&gt;path&lt;/code&gt; argument to &lt;code&gt;list.files()&lt;/code&gt; and also set &lt;code&gt;full.names&lt;/code&gt; to &lt;strong&gt;TRUE&lt;/strong&gt;. This latter argument will make &lt;code&gt;list.files()&lt;/code&gt; return the paths to the files you want to read in, rather than just the file names, which is needed for the function to import the data into R.&lt;/p&gt;
&lt;p&gt;This is my new favorite way of reading in multiple data files.&lt;/p&gt;
</description>
      </item>
      
    
  </channel>
</rss>
